<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
    <head>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta name="description" content="A blog by Yukun Guo on programming">

        <meta name="googlebot" content="noindex, nofollow" />
        <meta name="Googlebot-Mobile" content="noindex, nofollow" />
        <meta name="Bingbot" content="nocache" />
        <meta name="Baiduspider" content="noindex, nofollow" />
        <meta name="Sogou web spider" content="noindex, nofollow" />

        <title>gyk-notes - Clojure Parallelism for Side-effectful Blocking Operations</title>
        <link href="http://fonts.googleapis.com/css?family=Open+Sans:400italic,600italic,700italic,400,600,700" rel="stylesheet" type="text/css" />
        <link rel="stylesheet" type="text/css" href="../../../css/default.css" />
        <link rel="stylesheet" type="text/css" href="../../../css/syntax.css" />
    </head>
    <body>
        <div id="header">
            <div id="logo">
                <a href="../../../">gyk-notes</a>
            </div>
            <div id="navigation">
                <a href="../../../">Home</a>
                <a href="../../../about.html">About</a>
                <a href="../../../contact.html">Contact</a>
                <a href="../../../archive.html">Archive</a>
            </div>
        </div>
        <div class="sep-line"></div>
        <div id="content">
            <h1>Clojure Parallelism for Side-effectful Blocking Operations</h1>
            <div class="info">
    Posted on August 20, 2023
    
</div>
<div class="info">
    
    Tags: <a title="All pages tagged 'Code'." href="../../../tags/Code.html">Code</a>
    
</div>

<p>Currently we are working on a mobile app project with its backend written in Clojure. The backend service needs to perform some IO operations, e.g.,</p>
<ul>
<li>Upload files to cloud storage</li>
<li>Call a RESTful API for bunches of arguments</li>
</ul>
<p>Unfortunately, the SDK we use does not provide any non-blocking APIs. So, go-block is a no-go. Calling <code>(map upload-file! files)</code> <a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> loses the opportunity to run <code>upload-file!</code> in parallel. But Clojure provides a convenient way to make it parallel: <a href="https://clojuredocs.org/clojure.core/pmap"><code>pmap</code></a>. Just prepend <code>map</code> with letter <code>p</code>, with literally a single keystroke, you immediately solve the problem — or not?</p>
<p>It turns out such free lunch comes with a price. As Sean Corfield said in <a href="https://ask.clojure.org/index.php/8396/pmap-hard-wired-level-of-parallelism?show=8401#c8401">this post</a>, “pmap is a very blunt instrument and, although it can be a useful quick’n’dirty solution occasionally, you generally want to avoid it.” When doing my research, I found the article <a href="https://bsless.github.io/mapping-parallel-side-effects/">Idiomatic Clojure: Mixing Parallel Side Effects and Iteration</a> has nicely put the reasons against using <code>pmap</code> and discussed the alternatives. This post is basically my notes on reading it.</p>
<h2 id="how-pmap-works">How <code>pmap</code> works</h2>
<p>Take a look at the actual code of <code>pmap</code> from Clojure’s GitHub repo:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode clojure"><code class="sourceCode clojure"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true"></a>(<span class="bu">defn</span><span class="fu"> pmap</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true"></a>  [f coll]</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true"></a>  (<span class="kw">let</span> [n (<span class="kw">+</span> <span class="dv">2</span> (.. Runtime getRuntime availableProcessors))</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true"></a>        rets (<span class="kw">map</span> #(<span class="kw">future</span> (f <span class="va">%</span>)) coll)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true"></a>        step (<span class="kw">fn</span> step [[x &amp; xs <span class="at">:as</span> vs] fs]</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true"></a>               (<span class="kw">lazy-seq</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true"></a>                (<span class="kw">if-let</span> [s (<span class="kw">seq</span> fs)]</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true"></a>                  (<span class="kw">cons</span> (<span class="kw">deref</span> x) (step xs (<span class="kw">rest</span> s)))</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true"></a>                  (<span class="kw">map</span> <span class="kw">deref</span> vs))))]</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true"></a>    (step rets (<span class="kw">drop</span> n rets))))</span></code></pre></div>
<p>The implementation is concise but a bit tricky. Before delving into how it works, firstly, here is a refresher for <a href="https://clojuredocs.org/clojure.core/lazy-seq"><code>lazy-seq</code></a>, one of the fundamental building blocks for laziness in Clojure.</p>
<p><code>(lazy-seq &amp; body)</code> returns a <code>clojure.lang.LazySeq</code> which represents delayed computation. A <code>LazySeq</code> holds a reference to an <code>IFn</code> of <code>(fn [] body)</code> which evaluates to some <code>ISeq</code>, but it will only invoke the body <a href="https://github.com/clojure/clojure/blob/clojure-1.11.1/src/jvm/clojure/lang/LazySeq.java#L50C5-L50C5">the first time <code>seq</code> is called</a>. It is often used in tandem with <code>cons</code> to construct a lazy sequence.</p>
<p>This <a href="https://stackoverflow.com/a/12390331">StackOverflow</a> answer clarifies what <code>cons</code> is and how does it work with <code>lazy-seq</code>:</p>
<blockquote>
<p><code>cons</code> actually returns a <code>clojure.lang.Cons</code> object, which is what lazy sequences are made of. Note that <code>Cons</code> objects in Clojure are different from “cons cells” in other Lisps. A Clojure <code>Cons</code> takes an arbitrary <code>Object</code> as head, and an <code>ISeq</code> as tail. Since <code>Cons</code> itself implements <code>ISeq</code>, you can build sequences out of <code>Cons</code> objects. <code>clojure.lang.LazySeq</code> also implements <code>ISeq</code>, so it can be used as the tail of a <code>Cons</code>.</p>
</blockquote>
<p>To be a little more pedantic, the second argument to <code>cons</code> (the function) <a href="https://github.com/clojure/clojure/blob/clojure-1.11.1/src/jvm/clojure/lang/RT.java#L682">can also be <code>nil</code></a>, in order to make the end of a <em>proper</em> list:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode java"><code class="sourceCode java"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true"></a><span class="dt">static</span> <span class="kw">public</span> ISeq <span class="fu">cons</span>(<span class="bu">Object</span> x, <span class="bu">Object</span> coll){</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true"></a>    <span class="kw">if</span>(coll == <span class="kw">null</span>)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true"></a>        <span class="kw">return</span> <span class="kw">new</span> <span class="fu">PersistentList</span>(x);</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true"></a>    <span class="kw">else</span> <span class="kw">if</span>(coll <span class="kw">instanceof</span> ISeq)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true"></a>        <span class="kw">return</span> <span class="kw">new</span> <span class="fu">Cons</span>(x, (ISeq) coll);</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true"></a>    <span class="kw">else</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true"></a>        <span class="kw">return</span> <span class="kw">new</span> <span class="fu">Cons</span>(x, <span class="fu">seq</span>(coll));</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true"></a>}</span></code></pre></div>
<p>For demonstration, the following is a simplified implementation of <code>map</code> based on <code>lazy-seq</code> and <code>cons</code>:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode clojure"><code class="sourceCode clojure"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true"></a>(<span class="bu">defn</span><span class="fu"> my-map</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true"></a>  [f coll]</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true"></a>  (<span class="kw">lazy-seq</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true"></a>   (when-some [s (<span class="kw">seq</span> coll)]</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true"></a>     (<span class="kw">cons</span> (f (<span class="kw">first</span> s)) (my-map f (<span class="kw">rest</span> s))))))</span></code></pre></div>
<hr />
<p>Now back to <code>pmap</code> after the aside. <code>pmap</code> tries to run functions with a degree of parallelism of <code>#CPUs + 2</code>, referred as <code>n</code> in the code, trying to achieve optimum utilization, as stated in <a href="https://ask.clojure.org/index.php/8396/pmap-hard-wired-level-of-parallelism?show=8398#a8398"><em>Java Concurrency In Practice</em></a>.</p>
<p>In the second binding of <code>let</code> form, it sets up return values <code>rets</code> by <code>(map #(future (f %)) coll)</code>. Recalling <code>map</code> is lazy, here the realization of <code>future</code>s is postponed. Once evaluated, the future will be dispatched onto <code>clojure.lang.Agent/soloExecutor</code> for actual execution.</p>
<p>And then comes the <code>step</code> function. <code>step</code> takes two arguments: <code>vs</code>, the return values not yet consumed, and <code>fs</code>, the delayed futures not yet realized. It returns a lazy sequence by wrapping the code inside <code>lazy-seq</code>, so the results are computed on demand as they are accessed. However, we will see in a moment that <code>pmap</code> is actually semi-lazy.</p>
<p>In each step (hence the name), <code>step</code> calls <code>(seq fs)</code> to force the evaluation of the first element of <code>fs</code> should <code>fs</code> be non-empty, making a new computation of <code>f</code> take place. After that, it returns a list where the head is the head of <code>vs</code> <code>deref</code>ed, and the rest is composed by recursively calling <code>(step (rest vs) (rest fs))</code>. Note that if the caller tries to consume the head before the actual computation is done, it will block on the <code>deref</code>. Furthermore, in case <code>fs</code> is empty, it means the computation is almost finished, so the whole <code>vs</code> is <code>deref</code>ed and yielded.</p>
<p>Reaching the last line, the initial call to <code>step</code> is <code>(step rets (drop n rets))</code>. <code>rets</code> and <code>(drop n rets)</code> share the tail of sequence, except that <code>(drop n rets)</code> points to a position <code>n</code> elements ahead. <code>(drop n ...)</code> actually has the side effect of realizing the first <code>n</code> computations. This is the reason we call <code>pmap</code> “semi-lazy”, as the first <code>n</code> elements of <code>coll</code> are computed eagerly even before any consumption of results.</p>
<p><img src="./pmap1.svg" /></p>
<p>Supposing #CPUs = 2, <code>coll</code> is <code>(range 8)</code>, and diagram above shows how data are organized at the first call to <code>step</code>.</p>
<p>The diagram below shows what it looks like after the first step.</p>
<p><img src="./pmap2.svg" /></p>
<p>During the execution of <code>pmap</code>, it keeps an invariant of <code>(= (count vs) (+ (count fs) n))</code>, assuming the length of <code>coll</code> is at least <code>#CPUs + 2</code>.</p>
<h2 id="the-problems-with-pmap">The problems with <code>pmap</code></h2>
<p>The docstring of <code>pmap</code> somewhat sums up its shortcomings (emphasis mine):</p>
<blockquote>
<p>… <em>Semi-lazy</em> in that the parallel computation stays ahead of the consumption, but doesn’t realize the entire result unless required. Only useful for <em>computationally intensive</em> functions where the time of <code>f</code> dominates the <em>coordination overhead</em>.</p>
</blockquote>
<ul>
<li><p><em>Semi-lazy</em>: Not eager, not lazy, but in between. This will be a headache if your code relies on the side effects of the function calls. Parallel programming and laziness have intrinsically conflicting goals, which also places semi-laziness in some embarrassing position.</p></li>
<li><p>Only suitable for <em>computationally intensive</em> functions: Quoting <em>Java Concurrency In Practice</em>,</p>
<blockquote>
<p>Even compute-intensive threads occasionally take a page fault or pause for some other reason, so an “extra” runnable thread prevents CPU cycles from going unused when this happens.</p>
</blockquote>
<blockquote>
<p>For tasks that also include I/O or other blocking operations, you want a larger pool, since not all of the threads will be schedulable at all times.</p>
</blockquote>
<p><code>pmap</code> spawns a fixed number of <code>#CPUs + 2</code> threads, so it’s suboptimal for IO-bound operations.</p></li>
<li><p>If <code>f</code> is a lightweight, short-lived function despite being CPU-bound, and you use <code>pmap</code> in a tight loop, the <em>coordination overhead</em> may also neutralize the benefits of extra parallelism.</p></li>
</ul>
<p>Besides the above points, there are other drawbacks:</p>
<ul>
<li><p><code>pmap</code> uses <code>SoloExecutor</code> which is an unbounded thread pool (<a href="https://github.com/openjdk/jdk/blob/jdk-18%2B36/src/java.base/share/classes/java/util/concurrent/Executors.java#L217">OpenJDK code</a>):</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode java"><code class="sourceCode java"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true"></a><span class="kw">public</span> <span class="dt">static</span> <span class="bu">ExecutorService</span> <span class="fu">newCachedThreadPool</span>() {</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true"></a>    <span class="kw">return</span> <span class="kw">new</span> <span class="bu">ThreadPoolExecutor</span>(<span class="dv">0</span>, <span class="bu">Integer</span>.<span class="fu">MAX_VALUE</span>,</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true"></a>                                  <span class="dv">60L</span>, <span class="bu">TimeUnit</span>.<span class="fu">SECONDS</span>,</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true"></a>                                  <span class="kw">new</span> <span class="bu">SynchronousQueue</span>&lt;<span class="bu">Runnable</span>&gt;());</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true"></a>}</span></code></pre></div>
<p>If you call two <code>pmap</code>s consecutively, the second call may cause more threads spawned than expected.</p></li>
<li><p>No backpressure, as the thread pool can keep growing.</p></li>
<li><p>To make semi-laziness even more unpredictable, when chunked-seq is used the sequence is realized in chunks of 32 elements.</p></li>
<li><p><code>pmap</code> preserves order, sometimes it is unnecessary and may hinde on-time delivery to the downstream.</p></li>
</ul>
<h2 id="a-better-pmap">A better <code>pmap</code></h2>
<p>To recap, for IO-bound operations it is fundamentally wrong to choose the number of threads based on either the count of CPU cores, because it is not CPU-bound, or the count of the collection, because that may be a very large number. Instead, we should choose the number large enough to saturate the IO bandwidth, but not larger. Usually, the number is specific to the task at hand, and should be kept globally across the instance.</p>
<p>In case the number of requests in flight exceeds the designed degree of parallism, we have 3 choices:</p>
<ol type="1">
<li>Fail the request, e.g., returning 429 “Too Many Requests”.</li>
<li>Block the request.</li>
<li>Temporarily increase the thread number and handle the request in a newly-spawned thread.</li>
</ol>
<p>Nonetheless, <code>pmap</code> preferably should take an “all or nothing” approach, as it’s tricky to restore the side effects when <code>pmap</code> has failed partially.</p>
<p>Java’s built-in tools for concurrent programming is too powerful to ignore. Being able to push down the problem to the host platform of Java (JavaScript) for Clojure (ClojureScript) is an advantage. In this particular case, it means you can leverage the countless hours of manpower poured into Java’s concurrency libraries.</p>
<p>Solving the problem with <code>java.util.concurrent</code> by Clojure code that looks like Java code in disguise, is not ideal from a Clojure purist’s perspective, but let’s remember that Clojure running on the JVM is <strong>not</strong> an implementation detail, as stated by the BDFL himself:</p>
<blockquote>
<p>Clojure also is designed to run on the JVM. Being on the JVM is not an implementation detail. It is an objective.</p>
<p>— Rich Hickey, <em>Clojure – An Introduction for Lisp Programmers</em></p>
</blockquote>
<p>So I choose to go with the “Unbounded Queue” way as in <em>Idiomatic Clojure: Mixing Parallel Side Effects and Iteration</em>, only with slight modifications.</p>
<p>My <code>pmap</code> implementation firstly checks whether the number of enqueued tasks in <code>ThreadPoolExecutor</code>’s queue is really excessive and if so, fails the call as a whole:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode clojure"><code class="sourceCode clojure"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true"></a>(<span class="bu">defn</span><span class="fu"> submit</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true"></a>  [pool f]</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true"></a>  (.submit ^ExecutorService pool ^Callable f))</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true"></a></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true"></a>(<span class="bu">defn</span><span class="fu"> pmap*</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true"></a>  [f xs]</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true"></a>  (<span class="kw">if</span> (<span class="kw">&gt;</span> (.. <span class="at">@default-pool</span> getQueue size) threshold)</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true"></a>    (<span class="kw">throw</span> (RejectedExecutionException. <span class="st">&quot;Too many queued requests&quot;</span>))</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true"></a>    (<span class="kw">-&gt;&gt;</span> xs</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true"></a>         (<span class="kw">mapv</span> (<span class="kw">fn</span> [x] (submit <span class="at">@default-pool</span> #(f x))))</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true"></a>         (<span class="kw">mapv</span> <span class="kw">deref</span>))))</span></code></pre></div>
<p>The <code>default-pool</code> made by <code>newFixedThreadPool</code> uses unbounded <code>LinkedBlockingQueue</code>, contrary to <code>newCachedThreadPool</code>’s <code>SynchronousQueue</code> which behaves like a rendezvous channel.</p>
<table>
<thead>
<tr class="header">
<th>Thread pool type</th>
<th>Queue type</th>
<th>Queue size</th>
<th>#Workers</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>newFixedThreadPool</code></td>
<td><code>LinkedBlockingQueue</code></td>
<td>[0, +∞)</td>
<td>n</td>
</tr>
<tr class="even">
<td><code>newCachedThreadPool</code></td>
<td><code>SynchronousQueue</code></td>
<td>0</td>
<td>[0, +∞)</td>
</tr>
</tbody>
</table>
<p>(Not really ∞ but makes little difference in practice.)</p>
<p>The usage:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode clojure"><code class="sourceCode clojure"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true"></a>(<span class="kw">try</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true"></a>  (<span class="kw">let</span> [results (pmap* upload-file! files)]</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true"></a>    ...)</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true"></a>  (<span class="kw">catch</span> RejectedExecutionException rejected-ex</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true"></a>    <span class="co">; Returns 429 &quot;Too Many Requests&quot;</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true"></a>    ...))</span></code></pre></div>
<p>Finally, beware of the <a href="https://stackoverflow.com/questions/15485840/threadpoolexecutor-with-unbounded-queue-not-creating-new-threads">gotcha</a> of ThreadPoolExecutor with unbounded queue if you would like to configure <code>corePoolSize</code> smaller than <code>maxPoolSize</code>.</p>
<section class="footnotes" role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p>This is actually bad using <code>map</code> for side-effect. See <a href="https://bsless.github.io/side-effects/">Idiomatic Clojure: Mixing Side Effects and Iteration</a>.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

        </div>
        <div id="footer">
            Copyright &copy; 2015 - Yukun Guo -
            Powered by <a href="http://jaspervdj.be/hakyll">Hakyll</a>
        </div>

    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.0/dist/katex.min.css" integrity="sha384-BdGj8xC2eZkQaxoQ8nSLefg4AV4/AwB3Fj+8SUSo7pnKP6Eoy18liIKTPn9oBYNG" crossorigin="anonymous">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.0/dist/katex.min.js" integrity="sha384-JiKN5O8x9Hhs/UE5cT5AAJqieYlOZbGT3CHws/y97o3ty4R7/O5poG9F3JoiOYw1" crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.0/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous" onload="renderMathInElement(document.body,);"></script>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-KNSY6VRL5Y"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-KNSY6VRL5Y');
    </script>
    </body>
</html>
